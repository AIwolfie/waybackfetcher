
# ğŸ•¸ï¸ Wayback URL Fetcher

A blazing-fast Python CLI tool that fetches historical URLs from the **Wayback Machine (archive.org)** for a single domain or a list of domains â€” perfect for **bug bounty**, **OSINT**, and **web recon**.

Built by: **Mayank Malaviya** ([@AIwolfie](https://github.com/AIwolfie)) âš¡

---

## ğŸ“¦ Features

âœ… Fetch URLs archived by the Wayback Machine  
âœ… Supports single domain `-d` or list from file `-l`  
âœ… Multithreaded for fast execution  
âœ… Outputs unique URLs only  
âœ… Verbose mode to show live fetching  
âœ… Summary of total domains, URLs, and time taken  
âœ… Smart suggestions if no results found  
âœ… Built-in help menu and credits  

---

## ğŸš€ Installation

### 1. Clone or download this repo
```bash
git clone https://github.com/AIwolfie/waybackfetcher.git
cd waybackfetcher
````

### 2. Make the script executable

```bash
chmod +x waybackfetcher.py
```

### 3. (Optional) Install globally to use like a command

#### A. Move to `/usr/local/bin/`

```bash
sudo mv waybackfetcher.py /usr/local/bin/waybackfetcher
```

#### B. Or symlink if you still want to edit:

```bash
sudo ln -s $(pwd)/waybackfetcher.py /usr/local/bin/waybackfetcher
```

---

## ğŸ§ª Usage

### Single domain

```bash
waybackfetcher -d example.com -o urls.txt
```

### Multiple domains

```bash
waybackfetcher -l domains.txt -o results.txt
```

### Verbose output (shows URLs live + per-domain count)

```bash
waybackfetcher -l domains.txt -o results.txt -v
```

---

## ğŸ†˜ Help Menu

Run:

```bash
waybackfetcher -h
```

Output:

```
usage: waybackfetcher [-h] (-d DOMAIN | -l LIST) -o OUTPUT [-v]

ğŸ•¸ï¸ Wayback URL Fetcher - Fast historical URL fetcher from the Wayback Machine.

options:
  -h, --help        Show this help message and exit
  -d DOMAIN         Single domain (e.g. example.com)
  -l LIST           File containing domains (one per line)
  -o OUTPUT         Output file to save all unique URLs
  -v, --verbose     Show live URLs and per-domain counts
```

---

## ğŸ“¥ Output

* All URLs are saved to the file specified with `-o`
* Duplicates are removed
* Each run prints a summary including:

  * Domains processed
  * Total unique URLs
  * Time taken

---

## ğŸ§  Suggestions if no URLs are found

If you see:

```
[!] No URLs found for:
   - somedomain.com

ğŸ’¡ Tips:
   - Maybe itâ€™s a *new domain* (no archive yet).
   - Try *subdomain enumeration* for more data.
   - Check spelling or try alternative TLDs.
```

These are friendly hints to improve recon coverage.

---

## ğŸ§‘â€ğŸ’» Author

**ğŸ‘¨â€ğŸ’» Mayank Malaviya**

* GitHub: [AIwolfie](https://github.com/AIwolfie)
* Medium: [@mayankmalaviya](https://medium.com/@mayankmalaviya)
* LinkedIn: [Mayank's Profile](https://linkedin.com/in/mayank-malaviya)

---

## ğŸ“œ License

MIT License

---

## â˜• Like it?

Star it on GitHub and share with your recon team ğŸ–¤

```

---

Let me know if you want a `setup.sh` installer script that:
- Checks Python version
- Installs dependencies
- Installs the tool globally in one go.